{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading face detector...\n",
      "[INFO] loading face recognizer...\n",
      "[INFO] starting video stream...\n",
      "[INFO] elasped time: 6.12\n",
      "[INFO] approx. FPS: 12.59\n"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "from imutils.video import VideoStream\n",
    "from imutils.video import FPS\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import pickle\n",
    "import time\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "\n",
    "args = dict()\n",
    "args['detector'] = 'face_detection_model'\n",
    "args['embedding_model'] = 'openface_nn4.small2.v1.t7'\n",
    "args['recognizer']= 'output/recognizer.pickle'\n",
    "args['le'] = 'output/le.pickle'\n",
    "args['confidence'] = 0.5\n",
    "\n",
    "\n",
    "# load our serialized face detector from disk\n",
    "print(\"[INFO] loading face detector...\")\n",
    "protoPath = os.path.sep.join([args[\"detector\"], \"deploy.prototxt\"])\n",
    "modelPath = os.path.sep.join([args[\"detector\"],\n",
    "\t\"res10_300x300_ssd_iter_140000.caffemodel\"])\n",
    "detector = cv2.dnn.readNetFromCaffe(protoPath, modelPath)\n",
    "\n",
    "# load our serialized face embedding model from disk\n",
    "print(\"[INFO] loading face recognizer...\")\n",
    "embedder = cv2.dnn.readNetFromTorch(args[\"embedding_model\"])\n",
    "\n",
    "# load the actual face recognition model along with the label encoder\n",
    "recognizer = pickle.loads(open(args[\"recognizer\"], \"rb\").read())\n",
    "le = pickle.loads(open(args[\"le\"], \"rb\").read())\n",
    "\n",
    "# initialize the video stream, then allow the camera sensor to warm up\n",
    "print(\"[INFO] starting video stream...\")\n",
    "vs = VideoStream(src=0).start()\n",
    "time.sleep(2.0)\n",
    "\n",
    "# start the FPS throughput estimator\n",
    "fps = FPS().start()\n",
    "\n",
    "# loop over frames from the video file stream\n",
    "while True:\n",
    "\t# grab the frame from the threaded video stream\n",
    "\tframe = vs.read()\n",
    "\n",
    "\t# resize the frame to have a width of 600 pixels (while\n",
    "\t# maintaining the aspect ratio), and then grab the image\n",
    "\t# dimensions\n",
    "\tframe = imutils.resize(frame, width=600)\n",
    "\t(h, w) = frame.shape[:2]\n",
    "\n",
    "\t# construct a blob from the image\n",
    "\timageBlob = cv2.dnn.blobFromImage(\n",
    "\t\tcv2.resize(frame, (300, 300)), 1.0, (300, 300),\n",
    "\t\t(104.0, 177.0, 123.0), swapRB=False, crop=False)\n",
    "\n",
    "\t# apply OpenCV's deep learning-based face detector to localize\n",
    "\t# faces in the input image\n",
    "\tdetector.setInput(imageBlob)\n",
    "\tdetections = detector.forward()\n",
    "\n",
    "\t# loop over the detections\n",
    "\tfor i in range(0, detections.shape[2]):\n",
    "\t\t# extract the confidence (i.e., probability) associated with\n",
    "\t\t# the prediction\n",
    "\t\tconfidence = detections[0, 0, i, 2]\n",
    "\n",
    "\t\t# filter out weak detections\n",
    "\t\tif confidence > args[\"confidence\"]:\n",
    "\t\t\t# compute the (x, y)-coordinates of the bounding box for\n",
    "\t\t\t# the face\n",
    "\t\t\tbox = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "\t\t\t(startX, startY, endX, endY) = box.astype(\"int\")\n",
    "\n",
    "\t\t\t# extract the face ROI\n",
    "\t\t\tface = frame[startY:endY, startX:endX]\n",
    "\t\t\t(fH, fW) = face.shape[:2]\n",
    "\n",
    "\t\t\t# ensure the face width and height are sufficiently large\n",
    "\t\t\tif fW < 20 or fH < 20:\n",
    "\t\t\t\tcontinue\n",
    "\n",
    "\t\t\t# construct a blob for the face ROI, then pass the blob\n",
    "\t\t\t# through our face embedding model to obtain the 128-d\n",
    "\t\t\t# quantification of the face\n",
    "\t\t\tfaceBlob = cv2.dnn.blobFromImage(face, 1.0 / 255,\n",
    "\t\t\t\t(96, 96), (0, 0, 0), swapRB=True, crop=False)\n",
    "\t\t\tembedder.setInput(faceBlob)\n",
    "\t\t\tvec = embedder.forward()\n",
    "\n",
    "\t\t\t# perform classification to recognize the face\n",
    "\t\t\tpreds = recognizer.predict_proba(vec)[0]\n",
    "\t\t\tj = np.argmax(preds)\n",
    "\t\t\tproba = preds[j]\n",
    "\t\t\tname = le.classes_[j]\n",
    "\n",
    "\t\t\t# draw the bounding box of the face along with the\n",
    "\t\t\t# associated probability\n",
    "\t\t\ttext = \"{}: {:.2f}%\".format(name, proba * 100)\n",
    "\t\t\ty = startY - 10 if startY - 10 > 10 else startY + 10\n",
    "\t\t\tcv2.rectangle(frame, (startX, startY), (endX, endY),\n",
    "\t\t\t\t(0, 0, 255), 2)\n",
    "\t\t\tcv2.putText(frame, text, (startX, y),\n",
    "\t\t\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 0, 255), 2)\n",
    "\n",
    "\t# update the FPS counter\n",
    "\tfps.update()\n",
    "\n",
    "\t# show the output frame\n",
    "\tcv2.imshow(\"Frame\", frame)\n",
    "\tkey = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "\t# if the `q` key was pressed, break from the loop\n",
    "\tif key == ord(\"q\"):\n",
    "\t\tbreak\n",
    "\n",
    "# stop the timer and display FPS information\n",
    "fps.stop()\n",
    "print(\"[INFO] elasped time: {:.2f}\".format(fps.elapsed()))\n",
    "print(\"[INFO] approx. FPS: {:.2f}\".format(fps.fps()))\n",
    "\n",
    "# do a bit of cleanup\n",
    "cv2.destroyAllWindows()\n",
    "vs.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
